{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tree_sitter\n",
    "from tree_sitter import Language, Tree\n",
    "import json\n",
    "import tree_sitter\n",
    "import tree_sitter_java as tsjava\n",
    "\n",
    "lang_func_node = {\n",
    "    'python': ['function_definition'],\n",
    "    'c': ['function_definition'],\n",
    "    'cpp': ['function_definition'],\n",
    "    'java': ['method_declaration', 'constructor_declaration'],\n",
    "    'javascript': ['function_declaration']\n",
    "}\n",
    "\n",
    "def get_ast(code):\n",
    "    \"\"\"Parses a given Java code snippet and returns the AST using Tree-sitter.\"\"\"\n",
    "    JAVA_LANGUAGE = tree_sitter.Language(tsjava.language())\n",
    "    parser = tree_sitter.Parser(JAVA_LANGUAGE)\n",
    "    return parser.parse(code.encode('utf-8'))\n",
    "\n",
    "def get_nx_ast(code: str, lang: str):\n",
    "    ast = get_ast(code)\n",
    "    return ast\n",
    "\n",
    "def traverse_tree(tree: Tree):\n",
    "    cursor = tree.walk()\n",
    "\n",
    "    reached_root = False\n",
    "    while not reached_root:\n",
    "        yield cursor.node\n",
    "\n",
    "        if cursor.goto_first_child():\n",
    "            continue\n",
    "\n",
    "        if cursor.goto_next_sibling():\n",
    "            continue\n",
    "\n",
    "        retracing = True\n",
    "        while retracing:\n",
    "            if not cursor.goto_parent():\n",
    "                retracing = False\n",
    "                reached_root = True\n",
    "\n",
    "            if cursor.goto_next_sibling():\n",
    "                retracing = False\n",
    "      \n",
    "def _get_methods(ast, content, file_path, language):\n",
    "    methods = []\n",
    "    for node in traverse_tree(ast):\n",
    "            \n",
    "        if node.type in lang_func_node[language]:\n",
    "            method = {}\n",
    "\n",
    "            s, e = node.start_point[0] + 1, node.end_point[0] + 1\n",
    "\n",
    "            # Split the content into lines\n",
    "            lines = content.split('\\n')\n",
    "\n",
    "            # Extract lines from 's' to 'e'\n",
    "            selected_lines = lines[s-1:e]  # Adjust indices to 0-based if needed\n",
    "            selected_lines = [line.strip() for line in selected_lines]\n",
    "            # Join the selected lines back into a string\n",
    "            selected_content = ' '.join(selected_lines)\n",
    "\n",
    "            method['code'] = selected_content\n",
    "            method['path'] = file_path\n",
    "            method['start_line'] = s\n",
    "            method['end_line'] = e\n",
    "            method['nloc'] = len(lines)\n",
    "            method['token_count'] = len(selected_content)\n",
    "\n",
    "            methods.append(method)\n",
    "    return methods\n",
    " \n",
    "def get_all_methods(file_path):\n",
    "    try:\n",
    "        content = open(file_path, 'r').read()\n",
    "    except UnicodeDecodeError:\n",
    "        return None\n",
    "    ast = get_nx_ast(content, \"java\")\n",
    "    file_methods = _get_methods(ast, content, file_path, \"java\")                \n",
    "    return file_methods\n",
    "\n",
    "def find_method_with_lines(file_path, start_line, end_line):\n",
    "    methods = get_all_methods(file_path)\n",
    "    if methods is None:\n",
    "        return None, None, None\n",
    "    \n",
    "    for method in methods:\n",
    "        if method['start_line'] <= start_line and method['end_line'] >= end_line:\n",
    "            before = open(file_path, 'r').readlines()[method['start_line']-1:start_line-1]\n",
    "            after = open(file_path, 'r').readlines()[end_line-1:method['end_line']]\n",
    "            method['before'] = \"\\n\".join([line[:-1] for line in before])\n",
    "            method['after'] = \"\\n\".join([line[:-1] for line in after])\n",
    "            return method, method['start_line'], method['end_line'] + 1\n",
    "    return None, None, None\n",
    "\n",
    "def find_method_with_start_line(file_path, start_line):\n",
    "    methods = get_all_methods(file_path)\n",
    "    if methods is None:\n",
    "        return None, None, None\n",
    "    \n",
    "    for method in methods:\n",
    "        if method['start_line'] == start_line:\n",
    "            with open(file_path, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "            \n",
    "            method_code = ''.join(lines[start_line - 1: method['end_line']])  # Slicing from start to end\n",
    "            return method_code, method['start_line'], method['end_line'] + 1\n",
    "    return None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_1():\n",
    "    regminer4apr = \"/external_disk/coding_space/ChatRepairRegression/experiments/regminer4apr.json\"\n",
    "    environments = \"/external_disk/coding_space/ChatRepairRegression/experiments/environments\"\n",
    "\n",
    "    with open(regminer4apr, 'r') as f:\n",
    "        dataset = json.load(f)\n",
    "\n",
    "    for data in dataset:\n",
    "        id, relative_path = data.split(\"_\")\n",
    "        file_path = os.path.join(environments, f'RegressionBug-{id}', \"BUGGY\", relative_path)\n",
    "        bug_info = dataset[data]\n",
    "        method, method_start_line, method_end_line = find_method_with_lines(file_path, bug_info['start_line'], bug_info['end_line'])\n",
    "        \n",
    "        bug_info['start_line'] += 1\n",
    "        bug_info['end_line'] += 1\n",
    "\n",
    "        bug_info['method_start_line'] = method_start_line\n",
    "        bug_info['method_end_line'] = method_end_line\n",
    "    \n",
    "    # Write updated data back to the JSON file\n",
    "    with open(regminer4apr, 'w') as f:\n",
    "        json.dump(dataset, f, indent=4)\n",
    "\n",
    "# main_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "def main_2():\n",
    "    regminer4apr = \"/external_disk/coding_space/ChatRepairRegression/experiments/regminer4apr_function_level.json\"\n",
    "    environments = \"/external_disk/coding_space/ChatRepairRegression/experiments/environments/regminer4apr\"\n",
    "\n",
    "    with open(regminer4apr, 'r') as f:\n",
    "        dataset = json.load(f)\n",
    "\n",
    "    for data in dataset:\n",
    "        if dataset[data].get(\"before\") is not None:\n",
    "            continue\n",
    "        else:\n",
    "            id, relative_path = data.split(\"_\")\n",
    "            file_path = os.path.join(environments, f'RegressionBug-{id}', \"BUGGY\", relative_path)\n",
    "            bug_info = dataset[data]\n",
    "\n",
    "            method, method_start_line, method_end_line = find_method_with_start_line(file_path, bug_info['method_start_line'])\n",
    "            \n",
    "            # Create OrderedDict with your desired key order\n",
    "            ordered_bug_info = OrderedDict()\n",
    "            ordered_bug_info[\"context\"] = method\n",
    "            ordered_bug_info[\"start_line\"] = 0\n",
    "            ordered_bug_info[\"end_line\"] = 0\n",
    "            ordered_bug_info[\"bug_id\"] = str(id)\n",
    "            ordered_bug_info[\"before\"] = \"\"\n",
    "            ordered_bug_info[\"after\"] = \"\"\n",
    "            ordered_bug_info[\"buggy_line\"] = \"\"\n",
    "            ordered_bug_info[\"buggy_lines\"] = \"\"\n",
    "            ordered_bug_info[\"method_start_line\"] = method_start_line\n",
    "            ordered_bug_info[\"method_end_line\"] = method_end_line\n",
    "\n",
    "            # Update the dataset\n",
    "            dataset[data] = ordered_bug_info\n",
    "            break\n",
    "\n",
    "    # Write updated data back to the JSON file with ordered keys\n",
    "    with open(regminer4apr, 'w') as f:\n",
    "        json.dump(dataset, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "# main_2()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_method_info(code):\n",
    "    parser = Parser()\n",
    "    parser.set_language(JAVA_LANGUAGE)\n",
    "    \n",
    "    tree = parser.parse(code.encode())\n",
    "    root_node = tree.root_node\n",
    "\n",
    "    method_name = None\n",
    "    parameters = []\n",
    "\n",
    "    # Traverse tree to find method_declaration nodes\n",
    "    def traverse(node):\n",
    "        nonlocal method_name, parameters\n",
    "        if node.type == \"method_declaration\":\n",
    "            for child in node.children:\n",
    "                if child.type == \"identifier\":\n",
    "                    method_name = code[child.start_byte:child.end_byte]\n",
    "                elif child.type == \"formal_parameters\":\n",
    "                    for param in child.children:\n",
    "                        if param.type == \"formal_parameter\":\n",
    "                            param_text = code[param.start_byte:param.end_byte]\n",
    "                            parameters.append(param_text)\n",
    "        for child in node.children:\n",
    "            traverse(child)\n",
    "\n",
    "    traverse(root_node)\n",
    "    \n",
    "    return method_name, parameters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "common-libs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
